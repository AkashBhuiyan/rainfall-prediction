{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Station</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>AvgHumidity</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>StationIndex</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>Barisal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>Barisal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>Barisal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>Barisal</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>Barisal</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Station  Month  Day  Rainfall  AvgHumidity  AvgTemp  StationIndex  \\\n",
       "0  1970  Barisal      1    1         0           78     16.2             2   \n",
       "1  1970  Barisal      1    2         0           78     16.3             2   \n",
       "2  1970  Barisal      1    3         0           81     16.4             2   \n",
       "3  1970  Barisal      1    4         0           79     16.9             2   \n",
       "4  1970  Barisal      1    5         0           80     17.2             2   \n",
       "\n",
       "   class  label  \n",
       "0      0    0.0  \n",
       "1      0    0.0  \n",
       "2      0    0.0  \n",
       "3      0    0.0  \n",
       "4      0    0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('clean_rainfall_dataframe.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>AvgHumidity</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>StationIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day  Rainfall  AvgHumidity  AvgTemp  StationIndex\n",
       "0  1970      1    1         0           78     16.2             2\n",
       "1  1970      1    2         0           78     16.3             2\n",
       "2  1970      1    3         0           81     16.4             2\n",
       "3  1970      1    4         0           79     16.9             2\n",
       "4  1970      1    5         0           80     17.2             2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Station','class', 'label'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>AvgHumidity</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>StationIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day  AvgHumidity  AvgTemp  StationIndex\n",
       "0  1970      1    1           78     16.2             2\n",
       "1  1970      1    2           78     16.3             2\n",
       "2  1970      1    3           81     16.4             2\n",
       "3  1970      1    4           79     16.9             2\n",
       "4  1970      1    5           80     17.2             2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['Rainfall'], axis=1)\n",
    "y = data['Rainfall']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(X_train['Year']))\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6894918560922078\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4575b249ebba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#print the accuracy score of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LinearSVC accuracy : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc_model = LinearSVC(random_state=0)\n",
    "\n",
    "pred = svc_model.fit(X_train, y_train).predict(X_test)\n",
    "#print the accuracy score of the model\n",
    "print(\"LinearSVC accuracy : \",metrics.accuracy_score(y_test, pred, normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors accuracy score :  0.6667479560010782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the algorithm\n",
    "neigh.fit(X_train, y_train)\n",
    "# predict the response \n",
    "pred = neigh.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print (\"KNeighbors accuracy score : \",metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107908     90      0 ...      0      0      0]\n",
      " [  5348      3      0 ...      0      0      0]\n",
      " [  3633      2      0 ...      0      0      0]\n",
      " ...\n",
      " [     1      0      0 ...      0      0      0]\n",
      " [     1      0      0 ...      0      0      0]\n",
      " [     1      0      0 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82    107998\n",
      "           1       0.02      0.00      0.00      5351\n",
      "           2       0.00      0.00      0.00      3635\n",
      "           3       0.00      0.00      0.00      2970\n",
      "           4       0.00      0.00      0.00      2426\n",
      "           5       0.00      0.00      0.00      2092\n",
      "           6       0.00      0.00      0.00      1870\n",
      "           7       0.00      0.00      0.00      1574\n",
      "           8       0.00      0.00      0.00      1469\n",
      "           9       0.00      0.00      0.00      1280\n",
      "          10       0.00      0.00      0.00      1317\n",
      "          11       0.00      0.00      0.00      1136\n",
      "          12       0.00      0.00      0.00      1096\n",
      "          13       0.00      0.00      0.00       974\n",
      "          14       0.00      0.00      0.00       905\n",
      "          15       0.00      0.00      0.00       934\n",
      "          16       0.00      0.00      0.00       778\n",
      "          17       0.00      0.00      0.00       761\n",
      "          18       0.00      0.00      0.00       765\n",
      "          19       0.00      0.00      0.00       585\n",
      "          20       0.00      0.00      0.00       709\n",
      "          21       0.00      0.00      0.00       588\n",
      "          22       0.00      0.00      0.00       560\n",
      "          23       0.00      0.00      0.00       563\n",
      "          24       0.00      0.00      0.00       476\n",
      "          25       0.00      0.00      0.00       571\n",
      "          26       0.00      0.00      0.00       484\n",
      "          27       0.00      0.00      0.00       441\n",
      "          28       0.00      0.00      0.00       427\n",
      "          29       0.00      0.00      0.00       352\n",
      "          30       0.00      0.00      0.00       396\n",
      "          31       0.00      0.00      0.00       400\n",
      "          32       0.00      0.00      0.00       341\n",
      "          33       0.00      0.00      0.00       339\n",
      "          34       0.00      0.00      0.00       342\n",
      "          35       0.00      0.00      0.00       285\n",
      "          36       0.00      0.00      0.00       302\n",
      "          37       0.00      0.00      0.00       256\n",
      "          38       0.00      0.00      0.00       278\n",
      "          39       0.00      0.00      0.00       223\n",
      "          40       0.00      0.00      0.00       250\n",
      "          41       0.00      0.00      0.00       242\n",
      "          42       0.00      0.00      0.00       208\n",
      "          43       0.00      0.00      0.00       211\n",
      "          44       0.00      0.00      0.00       198\n",
      "          45       0.00      0.00      0.00       203\n",
      "          46       0.00      0.00      0.00       193\n",
      "          47       0.00      0.00      0.00       195\n",
      "          48       0.00      0.00      0.00       179\n",
      "          49       0.00      0.00      0.00       154\n",
      "          50       0.00      0.00      0.00       207\n",
      "          51       0.00      0.00      0.00       188\n",
      "          52       0.00      0.00      0.00       159\n",
      "          53       0.00      0.00      0.00       162\n",
      "          54       0.00      0.00      0.00       147\n",
      "          55       0.00      0.00      0.00       161\n",
      "          56       0.00      0.00      0.00       132\n",
      "          57       0.00      0.00      0.00       113\n",
      "          58       0.00      0.00      0.00       140\n",
      "          59       0.00      0.00      0.00        97\n",
      "          60       0.00      0.00      0.00       125\n",
      "          61       0.00      0.00      0.00       113\n",
      "          62       0.00      0.00      0.00       109\n",
      "          63       0.00      0.00      0.00       121\n",
      "          64       0.00      0.00      0.00       108\n",
      "          65       0.00      0.00      0.00       108\n",
      "          66       0.00      0.00      0.00        80\n",
      "          67       0.00      0.00      0.00        99\n",
      "          68       0.00      0.00      0.00        88\n",
      "          69       0.00      0.00      0.00        90\n",
      "          70       0.00      0.00      0.00        98\n",
      "          71       0.00      0.00      0.00        76\n",
      "          72       0.00      0.00      0.00        88\n",
      "          73       0.00      0.00      0.00        81\n",
      "          74       0.00      0.00      0.00        69\n",
      "          75       0.00      0.00      0.00        66\n",
      "          76       0.00      0.00      0.00        76\n",
      "          77       0.00      0.00      0.00        71\n",
      "          78       0.00      0.00      0.00        61\n",
      "          79       0.00      0.00      0.00        61\n",
      "          80       0.00      0.00      0.00        71\n",
      "          81       0.00      0.00      0.00        46\n",
      "          82       0.00      0.00      0.00        58\n",
      "          83       0.00      0.00      0.00        51\n",
      "          84       0.00      0.00      0.00        56\n",
      "          85       0.00      0.00      0.00        71\n",
      "          86       0.00      0.00      0.00        42\n",
      "          87       0.00      0.00      0.00        43\n",
      "          88       0.00      0.00      0.00        41\n",
      "          89       0.00      0.00      0.00        48\n",
      "          90       0.00      0.00      0.00        50\n",
      "          91       0.00      0.00      0.00        52\n",
      "          92       0.00      0.00      0.00        33\n",
      "          93       0.00      0.00      0.00        38\n",
      "          94       0.00      0.00      0.00        35\n",
      "          95       0.00      0.00      0.00        44\n",
      "          96       0.00      0.00      0.00        34\n",
      "          97       0.00      0.00      0.00        35\n",
      "          98       0.00      0.00      0.00        30\n",
      "          99       0.00      0.00      0.00        35\n",
      "         100       0.00      0.00      0.00        32\n",
      "         101       0.00      0.00      0.00        33\n",
      "         102       0.00      0.00      0.00        26\n",
      "         103       0.00      0.00      0.00        32\n",
      "         104       0.00      0.00      0.00        32\n",
      "         105       0.00      0.00      0.00        35\n",
      "         106       0.00      0.00      0.00        26\n",
      "         107       0.00      0.00      0.00        29\n",
      "         108       0.00      0.00      0.00        31\n",
      "         109       0.00      0.00      0.00        26\n",
      "         110       0.00      0.00      0.00        27\n",
      "         111       0.00      0.00      0.00        18\n",
      "         112       0.00      0.00      0.00        23\n",
      "         113       0.00      0.00      0.00        23\n",
      "         114       0.00      0.00      0.00        24\n",
      "         115       0.00      0.00      0.00        32\n",
      "         116       0.00      0.00      0.00        25\n",
      "         117       0.00      0.00      0.00        27\n",
      "         118       0.00      0.00      0.00        24\n",
      "         119       0.00      0.00      0.00        21\n",
      "         120       0.00      0.00      0.00        16\n",
      "         121       0.00      0.00      0.00        20\n",
      "         122       0.00      0.00      0.00        19\n",
      "         123       0.00      0.00      0.00        18\n",
      "         124       0.00      0.00      0.00        12\n",
      "         125       0.00      0.00      0.00        11\n",
      "         126       0.00      0.00      0.00        11\n",
      "         127       0.00      0.00      0.00        13\n",
      "         128       0.00      0.00      0.00        10\n",
      "         129       0.00      0.00      0.00        14\n",
      "         130       0.00      0.00      0.00        11\n",
      "         131       0.00      0.00      0.00        16\n",
      "         132       0.00      0.00      0.00        15\n",
      "         133       0.00      0.00      0.00        16\n",
      "         134       0.00      0.00      0.00         5\n",
      "         135       0.00      0.00      0.00        15\n",
      "         136       0.00      0.00      0.00         8\n",
      "         137       0.00      0.00      0.00        13\n",
      "         138       0.00      0.00      0.00         9\n",
      "         139       0.00      0.00      0.00         9\n",
      "         140       0.00      0.00      0.00        17\n",
      "         141       0.00      0.00      0.00        15\n",
      "         142       0.00      0.00      0.00        11\n",
      "         143       0.00      0.00      0.00         8\n",
      "         144       0.00      0.00      0.00        15\n",
      "         145       0.00      0.00      0.00         9\n",
      "         146       0.00      0.00      0.00        13\n",
      "         147       0.00      0.00      0.00         3\n",
      "         148       0.00      0.00      0.00         9\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      0.00      0.00        11\n",
      "         151       0.00      0.00      0.00         5\n",
      "         152       0.00      0.00      0.00         9\n",
      "         153       0.00      0.00      0.00         5\n",
      "         154       0.00      0.00      0.00         9\n",
      "         155       0.00      0.00      0.00        11\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         7\n",
      "         159       0.00      0.00      0.00         6\n",
      "         160       0.00      0.00      0.00         6\n",
      "         161       0.00      0.00      0.00         7\n",
      "         162       0.00      0.00      0.00         3\n",
      "         163       0.00      0.00      0.00         5\n",
      "         164       0.00      0.00      0.00         5\n",
      "         165       0.00      0.00      0.00         5\n",
      "         166       0.00      0.00      0.00         4\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.00      0.00      0.00         6\n",
      "         169       0.00      0.00      0.00         7\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         5\n",
      "         172       0.00      0.00      0.00         5\n",
      "         173       0.00      0.00      0.00         9\n",
      "         174       0.00      0.00      0.00         5\n",
      "         175       0.00      0.00      0.00         8\n",
      "         176       0.00      0.00      0.00         4\n",
      "         177       0.00      0.00      0.00         5\n",
      "         178       0.00      0.00      0.00         7\n",
      "         179       0.00      0.00      0.00         8\n",
      "         180       0.00      0.00      0.00         4\n",
      "         181       0.00      0.00      0.00         5\n",
      "         182       0.00      0.00      0.00         4\n",
      "         183       0.00      0.00      0.00         2\n",
      "         184       0.00      0.00      0.00         5\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.00      0.00      0.00         5\n",
      "         187       0.00      0.00      0.00         4\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         4\n",
      "         191       0.00      0.00      0.00         4\n",
      "         192       0.00      0.00      0.00         2\n",
      "         193       0.00      0.00      0.00         4\n",
      "         194       0.00      0.00      0.00         3\n",
      "         195       0.00      0.00      0.00         3\n",
      "         196       0.00      0.00      0.00         3\n",
      "         197       0.00      0.00      0.00         3\n",
      "         198       0.00      0.00      0.00         3\n",
      "         199       0.00      0.00      0.00         4\n",
      "         200       0.00      0.00      0.00         6\n",
      "         201       0.00      0.00      0.00         7\n",
      "         202       0.00      0.00      0.00         6\n",
      "         203       0.00      0.00      0.00         3\n",
      "         204       0.00      0.00      0.00         3\n",
      "         205       0.00      0.00      0.00         3\n",
      "         206       0.00      0.00      0.00         6\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         2\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         8\n",
      "         211       0.00      0.00      0.00         3\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         3\n",
      "         215       0.00      0.00      0.00         3\n",
      "         216       0.00      0.00      0.00         3\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         4\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         1\n",
      "         223       0.00      0.00      0.00         4\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         4\n",
      "         226       0.00      0.00      0.00         3\n",
      "         227       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       0.00      0.00      0.00         3\n",
      "         231       0.00      0.00      0.00         3\n",
      "         233       0.00      0.00      0.00         2\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         3\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         2\n",
      "         242       0.00      0.00      0.00         2\n",
      "         243       0.00      0.00      0.00         2\n",
      "         245       0.00      0.00      0.00         1\n",
      "         246       0.00      0.00      0.00         1\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         2\n",
      "         250       0.00      0.00      0.00         2\n",
      "         251       0.00      0.00      0.00         1\n",
      "         252       0.00      0.00      0.00         2\n",
      "         253       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         3\n",
      "         255       0.00      0.00      0.00         1\n",
      "         256       0.00      0.00      0.00         2\n",
      "         257       0.00      0.00      0.00         2\n",
      "         258       0.00      0.00      0.00         2\n",
      "         259       0.00      0.00      0.00         1\n",
      "         261       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         3\n",
      "         269       0.00      0.00      0.00         1\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         272       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         274       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         1\n",
      "         280       0.00      0.00      0.00         2\n",
      "         300       0.00      0.00      0.00         1\n",
      "         302       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         1\n",
      "         320       0.00      0.00      0.00         1\n",
      "         324       0.00      0.00      0.00         1\n",
      "         325       0.00      0.00      0.00         1\n",
      "         331       0.00      0.00      0.00         1\n",
      "         333       0.00      0.00      0.00         1\n",
      "         334       0.00      0.00      0.00         1\n",
      "         335       0.00      0.00      0.00         2\n",
      "         339       0.00      0.00      0.00         1\n",
      "         362       0.00      0.00      0.00         1\n",
      "         366       0.00      0.00      0.00         1\n",
      "         370       0.00      0.00      0.00         1\n",
      "         371       0.00      0.00      0.00         1\n",
      "         379       0.00      0.00      0.00         1\n",
      "         381       0.00      0.00      0.00         1\n",
      "         391       0.00      0.00      0.00         1\n",
      "         395       0.00      0.00      0.00         1\n",
      "         399       0.00      0.00      0.00         1\n",
      "         407       0.00      0.00      0.00         1\n",
      "         422       0.00      0.00      0.00         1\n",
      "         425       0.00      0.00      0.00         1\n",
      "         481       0.00      0.00      0.00         1\n",
      "         508       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.69      0.69      0.69    155822\n",
      "   macro avg       0.00      0.00      0.00    155822\n",
      "weighted avg       0.48      0.69      0.57    155822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "# logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('Log_ROC')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.06\n"
     ]
    }
   ],
   "source": [
    "y_pred = linreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
